{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8-15_distribution_based_on_patients.ipynb","provenance":[{"file_id":"1_fPYDAuPLzF0vpCPOHrE4SmoMQCgYOtJ","timestamp":1584634109881},{"file_id":"1u1nyzUiksoQSyQ32BiiIN7MvyHUpwlj8","timestamp":1583162446019},{"file_id":"1TQZHVvw5A_VIiS0kH4RpbHmJdwFGy1Rj","timestamp":1576672623274}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"O4NygAiqvJAd","colab_type":"code","outputId":"f3c9529e-b40a-4f5b-d982-d15857d568c5","executionInfo":{"status":"ok","timestamp":1590410278239,"user_tz":-120,"elapsed":1298,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# !pip install import-ipynb\n","# import import_ipynb\n","\n","%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TZBS1XpfL2DD","colab_type":"code","outputId":"bdd332de-3663-4da9-ca89-721da690113c","executionInfo":{"status":"ok","timestamp":1590410310056,"user_tz":-120,"elapsed":32215,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"source":["\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.utils import shuffle\n","from sklearn.metrics import r2_score\n","import matplotlib.pyplot as plt \n","from keras.models import Model, Sequential \n","from keras.layers import Conv1D,Flatten,Conv2D, Dropout, MaxPooling2D, Input,Conv3D, MaxPooling3D, Dense, BatchNormalization\n","from keras.layers.merge import concatenate \n","from keras.layers import Flatten \n","from google.colab import drive\n","from keras.layers import Conv2D\n","from keras.optimizers import Adam\n","from keras.wrappers.scikit_learn import KerasClassifier,KerasRegressor\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","drive.mount('/content/drive')\n","# %cp -av fromfolder tofolder\n","# %cd \"/content/drive/My Drive/Newdata/\"\n","# from model_functions import *"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Brs9yjkr7gdW","colab_type":"text"},"source":["# 载入数据\n"]},{"cell_type":"code","metadata":{"id":"slWLE4HkwoHP","colab_type":"code","colab":{}},"source":["train_data = np.load('/content/drive/My Drive/Newdata/ordered_by_patient/按照病人prepost推fu/train_data_4.npy')\n","train_label = np.load('/content/drive/My Drive/Newdata/ordered_by_patient/按照病人prepost推fu/train_label_4.npy')\n","test_data =  np.load('/content/drive/My Drive/Newdata/ordered_by_patient/按照病人prepost推fu/test_data_4.npy')\n","test_label = np.load('/content/drive/My Drive/Newdata/ordered_by_patient/按照病人prepost推fu/test_label_4.npy')\n","\n","\n","train_data = train_data[:,8:14,:,:]\n","\n","test_data = test_data[:,8:14,:,:]\n","\n","train_data = np.reshape(train_data,(2700,6,116,116,1))\n","test_data = np.reshape(test_data,(900,6,116,116,1)) \n","\n","print(train_data.shape)\n","print(train_label.shape)\n","print(test_data.shape)\n","print(test_label.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Krrs44m-7vXH","colab_type":"text"},"source":["# 模型部分"]},{"cell_type":"code","metadata":{"id":"QKXSwj_ymPvv","colab_type":"code","colab":{}},"source":["def Model():\n","  model = Sequential()\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(6,116,116, 1)))\n","  model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.3))\n","  model.add(Conv3D(10, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization()) \n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(20, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  # model.add(Dropout(0.5))\n","  model.add(BatchNormalization())\n","  model.add(Conv3D(30, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(40, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(50, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(60, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(70, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(80, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(90, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(100, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(120, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(140, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(160, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(180, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(200, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(400, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(200, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(180, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(100, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  # model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  # model.add(BatchNormalization())\n","  # # model.add(Dropout(0.5))\n","  # model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  # model.add(BatchNormalization())\n","  # # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Conv3D(1, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(MaxPooling3D(pool_size=(1, 1, 1)))\n","  model.add(BatchNormalization())\n","  # model.add(Dropout(0.5))\n","  model.add(Flatten())\n","  # model.add(Dense(3200, activation='relu', kernel_initializer='he_uniform'))\n","  model.add(Dense(1028, activation='relu', kernel_initializer='he_uniform'))\n","  model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n","  model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n","  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n","  # model.add(Dense(3, activation='softmax'))\n","  model.add(Dense(3))\n","  model.summary()\n","  from keras.optimizers import RMSprop,Adam\n","  model.compile(optimizer = Adam(lr=0.0001),\n","                loss = 'mean_squared_error',\n","                metrics = ['mae'])\n","  return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2suX5KDLTCy0","colab_type":"code","colab":{}},"source":["\n","# data = np.load('/content/drive/My Drive/Newdata/shuffle_originalin3600.npy')\n","# label =  np.load('/content/drive/My Drive/Newdata/shuffle_originalout3600.npy')\n","# k = 5\n","# num_val_samples = len(data)//k\n","# # for i in range(k):\n","# i = 2\n","# print('processing fold #', i)\n","# test_data = data[i * num_val_samples: (i + 1) * num_val_samples]\n","# test_label = label[i * num_val_samples: (i + 1) * num_val_samples]\n","# train_data = np.concatenate([data[:i * num_val_samples],data[(i + 1) * num_val_samples:]], axis=0)\n","# train_label = np.concatenate([label[:i * num_val_samples],label[(i + 1) * num_val_samples:]], axis=0)\n","# np.save('/content/drive/My Drive/Newdata/'+str(i)+'_fold_trainin_original3600', train_data)\n","# # np.save('/content/drive/My Drive/Newdata/'+str(i)+'_fold_trainout_original3600', train_label)\n","# # np.save('/content/drive/My Drive/Newdata/'+str(i)+'_fold_testin_original3600', test_data)\n","# # np.save('/content/drive/My Drive/Newdata/'+str(i)+'_fold_testout_original3600', test_label)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J8qRk4hF73RM","colab_type":"text"},"source":["# 跑模型"]},{"cell_type":"code","metadata":{"id":"P-hMJ_1Mw-qT","colab_type":"code","outputId":"7248b29f-15cf-413d-f7aa-4fd09f75d04d","executionInfo":{"status":"error","timestamp":1590394797689,"user_tz":-120,"elapsed":60899,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["num_epochs = 50\n","batchsize = 12\n","model = Model()\n","history = model.fit(train_data, train_label, epochs=num_epochs, batch_size=batchsize, verbose=1)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv3d_1 (Conv3D)            (None, 6, 114, 114, 1)    10        \n","_________________________________________________________________\n","max_pooling3d_1 (MaxPooling3 (None, 6, 114, 114, 1)    0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 6, 114, 114, 1)    4         \n","_________________________________________________________________\n","conv3d_2 (Conv3D)            (None, 6, 112, 112, 10)   100       \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 6, 112, 112, 10)   40        \n","_________________________________________________________________\n","conv3d_3 (Conv3D)            (None, 6, 110, 110, 20)   1820      \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 6, 110, 110, 20)   80        \n","_________________________________________________________________\n","conv3d_4 (Conv3D)            (None, 6, 108, 108, 30)   5430      \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 6, 108, 108, 30)   120       \n","_________________________________________________________________\n","conv3d_5 (Conv3D)            (None, 6, 106, 106, 40)   10840     \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 6, 106, 106, 40)   160       \n","_________________________________________________________________\n","conv3d_6 (Conv3D)            (None, 6, 104, 104, 50)   18050     \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 6, 104, 104, 50)   200       \n","_________________________________________________________________\n","conv3d_7 (Conv3D)            (None, 6, 102, 102, 60)   27060     \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 6, 102, 102, 60)   240       \n","_________________________________________________________________\n","conv3d_8 (Conv3D)            (None, 6, 100, 100, 70)   37870     \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 6, 100, 100, 70)   280       \n","_________________________________________________________________\n","conv3d_9 (Conv3D)            (None, 6, 98, 98, 80)     50480     \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 6, 98, 98, 80)     320       \n","_________________________________________________________________\n","conv3d_10 (Conv3D)           (None, 6, 96, 96, 90)     64890     \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 6, 96, 96, 90)     360       \n","_________________________________________________________________\n","conv3d_11 (Conv3D)           (None, 6, 94, 94, 100)    81100     \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 6, 94, 94, 100)    400       \n","_________________________________________________________________\n","conv3d_12 (Conv3D)           (None, 6, 92, 92, 120)    108120    \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 6, 92, 92, 120)    480       \n","_________________________________________________________________\n","conv3d_13 (Conv3D)           (None, 6, 90, 90, 140)    151340    \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 6, 90, 90, 140)    560       \n","_________________________________________________________________\n","conv3d_14 (Conv3D)           (None, 6, 88, 88, 160)    201760    \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 6, 88, 88, 160)    640       \n","_________________________________________________________________\n","conv3d_15 (Conv3D)           (None, 6, 86, 86, 180)    259380    \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 6, 86, 86, 180)    720       \n","_________________________________________________________________\n","conv3d_16 (Conv3D)           (None, 6, 84, 84, 200)    324200    \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 6, 84, 84, 200)    800       \n","_________________________________________________________________\n","conv3d_17 (Conv3D)           (None, 6, 82, 82, 400)    720400    \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 6, 82, 82, 400)    1600      \n","_________________________________________________________________\n","conv3d_18 (Conv3D)           (None, 6, 80, 80, 200)    720200    \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 6, 80, 80, 200)    800       \n","_________________________________________________________________\n","conv3d_19 (Conv3D)           (None, 6, 78, 78, 180)    324180    \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 6, 78, 78, 180)    720       \n","_________________________________________________________________\n","conv3d_20 (Conv3D)           (None, 6, 76, 76, 100)    162100    \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 6, 76, 76, 100)    400       \n","_________________________________________________________________\n","conv3d_21 (Conv3D)           (None, 6, 74, 74, 1)      901       \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 6, 74, 74, 1)      4         \n","_________________________________________________________________\n","conv3d_22 (Conv3D)           (None, 6, 72, 72, 1)      10        \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 6, 72, 72, 1)      4         \n","_________________________________________________________________\n","conv3d_23 (Conv3D)           (None, 6, 70, 70, 1)      10        \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 6, 70, 70, 1)      4         \n","_________________________________________________________________\n","conv3d_24 (Conv3D)           (None, 6, 68, 68, 1)      10        \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 6, 68, 68, 1)      4         \n","_________________________________________________________________\n","conv3d_25 (Conv3D)           (None, 6, 66, 66, 1)      10        \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 6, 66, 66, 1)      4         \n","_________________________________________________________________\n","conv3d_26 (Conv3D)           (None, 6, 64, 64, 1)      10        \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 6, 64, 64, 1)      4         \n","_________________________________________________________________\n","conv3d_27 (Conv3D)           (None, 6, 62, 62, 1)      10        \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 6, 62, 62, 1)      4         \n","_________________________________________________________________\n","conv3d_28 (Conv3D)           (None, 6, 60, 60, 1)      10        \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 6, 60, 60, 1)      4         \n","_________________________________________________________________\n","conv3d_29 (Conv3D)           (None, 6, 58, 58, 1)      10        \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 6, 58, 58, 1)      4         \n","_________________________________________________________________\n","conv3d_30 (Conv3D)           (None, 6, 56, 56, 1)      10        \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 6, 56, 56, 1)      4         \n","_________________________________________________________________\n","conv3d_31 (Conv3D)           (None, 6, 54, 54, 1)      10        \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 6, 54, 54, 1)      4         \n","_________________________________________________________________\n","conv3d_32 (Conv3D)           (None, 6, 52, 52, 1)      10        \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 6, 52, 52, 1)      4         \n","_________________________________________________________________\n","conv3d_33 (Conv3D)           (None, 6, 50, 50, 1)      10        \n","_________________________________________________________________\n","batch_normalization_33 (Batc (None, 6, 50, 50, 1)      4         \n","_________________________________________________________________\n","conv3d_34 (Conv3D)           (None, 6, 48, 48, 1)      10        \n","_________________________________________________________________\n","batch_normalization_34 (Batc (None, 6, 48, 48, 1)      4         \n","_________________________________________________________________\n","conv3d_35 (Conv3D)           (None, 6, 46, 46, 1)      10        \n","_________________________________________________________________\n","batch_normalization_35 (Batc (None, 6, 46, 46, 1)      4         \n","_________________________________________________________________\n","conv3d_36 (Conv3D)           (None, 6, 44, 44, 1)      10        \n","_________________________________________________________________\n","batch_normalization_36 (Batc (None, 6, 44, 44, 1)      4         \n","_________________________________________________________________\n","conv3d_37 (Conv3D)           (None, 6, 42, 42, 1)      10        \n","_________________________________________________________________\n","batch_normalization_37 (Batc (None, 6, 42, 42, 1)      4         \n","_________________________________________________________________\n","conv3d_38 (Conv3D)           (None, 6, 40, 40, 1)      10        \n","_________________________________________________________________\n","batch_normalization_38 (Batc (None, 6, 40, 40, 1)      4         \n","_________________________________________________________________\n","conv3d_39 (Conv3D)           (None, 6, 38, 38, 1)      10        \n","_________________________________________________________________\n","batch_normalization_39 (Batc (None, 6, 38, 38, 1)      4         \n","_________________________________________________________________\n","conv3d_40 (Conv3D)           (None, 6, 36, 36, 1)      10        \n","_________________________________________________________________\n","batch_normalization_40 (Batc (None, 6, 36, 36, 1)      4         \n","_________________________________________________________________\n","conv3d_41 (Conv3D)           (None, 6, 34, 34, 1)      10        \n","_________________________________________________________________\n","batch_normalization_41 (Batc (None, 6, 34, 34, 1)      4         \n","_________________________________________________________________\n","conv3d_42 (Conv3D)           (None, 6, 32, 32, 1)      10        \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 6, 32, 32, 1)      4         \n","_________________________________________________________________\n","conv3d_43 (Conv3D)           (None, 6, 30, 30, 1)      10        \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 6, 30, 30, 1)      4         \n","_________________________________________________________________\n","conv3d_44 (Conv3D)           (None, 6, 28, 28, 1)      10        \n","_________________________________________________________________\n","batch_normalization_44 (Batc (None, 6, 28, 28, 1)      4         \n","_________________________________________________________________\n","conv3d_45 (Conv3D)           (None, 6, 26, 26, 1)      10        \n","_________________________________________________________________\n","batch_normalization_45 (Batc (None, 6, 26, 26, 1)      4         \n","_________________________________________________________________\n","conv3d_46 (Conv3D)           (None, 6, 24, 24, 1)      10        \n","_________________________________________________________________\n","batch_normalization_46 (Batc (None, 6, 24, 24, 1)      4         \n","_________________________________________________________________\n","conv3d_47 (Conv3D)           (None, 6, 22, 22, 1)      10        \n","_________________________________________________________________\n","batch_normalization_47 (Batc (None, 6, 22, 22, 1)      4         \n","_________________________________________________________________\n","conv3d_48 (Conv3D)           (None, 6, 20, 20, 1)      10        \n","_________________________________________________________________\n","batch_normalization_48 (Batc (None, 6, 20, 20, 1)      4         \n","_________________________________________________________________\n","conv3d_49 (Conv3D)           (None, 6, 18, 18, 1)      10        \n","_________________________________________________________________\n","batch_normalization_49 (Batc (None, 6, 18, 18, 1)      4         \n","_________________________________________________________________\n","conv3d_50 (Conv3D)           (None, 6, 16, 16, 1)      10        \n","_________________________________________________________________\n","batch_normalization_50 (Batc (None, 6, 16, 16, 1)      4         \n","_________________________________________________________________\n","conv3d_51 (Conv3D)           (None, 6, 14, 14, 1)      10        \n","_________________________________________________________________\n","batch_normalization_51 (Batc (None, 6, 14, 14, 1)      4         \n","_________________________________________________________________\n","conv3d_52 (Conv3D)           (None, 6, 12, 12, 1)      10        \n","_________________________________________________________________\n","batch_normalization_52 (Batc (None, 6, 12, 12, 1)      4         \n","_________________________________________________________________\n","conv3d_53 (Conv3D)           (None, 6, 10, 10, 1)      10        \n","_________________________________________________________________\n","batch_normalization_53 (Batc (None, 6, 10, 10, 1)      4         \n","_________________________________________________________________\n","conv3d_54 (Conv3D)           (None, 6, 8, 8, 1)        10        \n","_________________________________________________________________\n","batch_normalization_54 (Batc (None, 6, 8, 8, 1)        4         \n","_________________________________________________________________\n","conv3d_55 (Conv3D)           (None, 6, 6, 6, 1)        10        \n","_________________________________________________________________\n","batch_normalization_55 (Batc (None, 6, 6, 6, 1)        4         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 216)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1028)              223076    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               526848    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 4,194,170\n","Trainable params: 4,189,638\n","Non-trainable params: 4,532\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9bad151d239b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[12,180,6,78,78] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/conv3d_20/convolution_grad/Conv3DBackpropInputV2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"]}]},{"cell_type":"code","metadata":{"id":"vsBeoUbp6n1y","colab_type":"code","colab":{}},"source":["mse_history = history.history['loss']\n","mae_history = history.history['mae']\n","\n","epochs = range(1,len(mse_history) +1)\n","plt.plot(epochs, mse_history, 'c', label='mse')\n","plt.plot(epochs, mae_history, 'm', label='mae')\n","\n","# plt.savefig('/content/drive/My Drive/original4800_50epo_mse_mae1.png' ,dpi=1200)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBSqddWW0Og_","colab_type":"code","colab":{}},"source":["\n","comparision1 = (model.predict(test_data))*100\n","Test_label = test_label*100\n","# comparision1 , Test_label = shuffle(comparision1, Test_label)\n","x_data = range(900)\n","y_data_c1 = Test_label[:,0]\n","y_data_c2 = Test_label[:,1]\n","y_data_c3 = Test_label[:,2]\n","y_predict1_c1 = comparision1[:,0]\n","y_predict1_c2 = comparision1[:,1]\n","y_predict1_c3 = comparision1[:,2]\n","\n","fig, (predict_c1, predict_c2, predict_c3) = plt.subplots(3,figsize=(18,6))\n","fig.suptitle('3 visual conditions_changed') \n","\n","predict_c1.plot(x_data, y_data_c1 , 'r', label='truth_c1')\n","predict_c2.plot(x_data, y_data_c2 , 'r', label='truth_c2')\n","predict_c3.plot(x_data, y_data_c3 , 'r', label='truth_c3')\n","predict_c1.plot(x_data, y_predict1_c1 , 'g', label='predict1_c1')\n","predict_c2.plot(x_data, y_predict1_c2 , 'g', label='predict1_c2')\n","predict_c3.plot(x_data, y_predict1_c3 , 'g', label='predict1_c3')\n","predict_c1.legend(bbox_to_anchor=(0.9, 1), loc='upper left', borderaxespad=0.)\n","predict_c2.legend(bbox_to_anchor=(0.9, 1), loc='upper left', borderaxespad=0.)\n","predict_c3.legend(bbox_to_anchor=(0.9, 1), loc='upper left', borderaxespad=0.)\n","\n","# plt.savefig('/content/drive/My Drive/original4800_50epo_comparison1.png' ,dpi=1200)\n","\n","r2_score(Test_label, comparision1, multioutput='raw_values')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1jNwdfdjgC0","colab_type":"code","colab":{}},"source":["# data = np.load('/content/drive/My Drive/Newdata/shuffle_changedin4800.npy')\n","label = np.load('/content/drive/My Drive/Newdata/shuffle_changedout4800.npy')\n","data = np.reshape(data,(4800,30,116,116,1))\n","split_rate= 0.7\n","split = int(split_rate*4800)\n","train_data = data[:split]\n","train_label = label[:split]\n","test_data = data[split:]\n","test_label = label[split:] \n","\n","\n","def k_fold(k,train_data,train_targets):\n","  num_val_samples = len(train_data)//k\n","  val_mses = []\n","  val_maes = []\n","  mse_History = []\n","  mae_History = []\n","  num_epochs = 50\n","  batchsize = 6\n","  R2 = []\n","  Comparision = []\n","  for i in range(k):\n","    print('processing fold #', i)\n","    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n","    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]], axis=0)\n","    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]], axis=0)\n","    model = Model()\n","    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=batchsize, verbose=0)\n","    comparision1 = (model.predict(test_data))*100\n","    Test_label = test_label*100\n","    Comparision.append(comparision1)\n","    # r2_score(Test_label, comparision1, multioutput='raw_values')\n","    R2.append(r2_score(Test_label, comparision1, multioutput='raw_values'))\n","    # val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n","    # mse_history = history.history['loss']\n","    # mae_history = history.history['mean_absolute_error']\n","    # val_mses.append(val_mse)\n","    # val_maes.append(val_mae)\n","    # mse_History.append(mse_history)\n","    # mae_History.append(mae_history)\n","  # return val_mses, val_maes, mse_History, mae_History\n","  return  R2,Comparision\n","\n","R2_score, Predict_results = k_fold(5,train_data,train_label)\n","\n","\n","# average_mae_history = [(np.mean([x[i] for x in mae_history]))*100 for i in range(50)] \n","# average_mse_history = [(np.mean([x[i] for x in mse_history]))*100 for i in range(50)] \n","# #model 3Dcnn \n","# epochs = range(1,len(average_mse_history)+1)\n","# plt.plot(epochs, average_mae_history,'c',  label='mae' )\n","# plt.plot(epochs, average_mse_history,'m',  label='mse' )\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Validation')\n","# plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"InwlBzyiKeCq","colab_type":"code","colab":{}},"source":["mse_history = history.history['loss']\n","mae_history = history.history['mean_absolute_error'] \n","comparision1 = (model.predict(test_data[:100]))*100\n","x_data = range(1080)\n","Test_label = test_label[:100]*100\n","y_data_c1 = Test_label[:,0]\n","y_data_c2 = Test_label[:,1]\n","y_data_c3 = Test_label[:,2]\n","y_predict1_c1 = comparision1[:,0]\n","y_predict1_c2 = comparision1[:,1]\n","y_predict1_c3 = comparision1[:,2]\n","\n","fig, (predict_c1, predict_c2, predict_c3) = plt.subplots(3)\n","fig.suptitle('3 visual conditions') \n","plt.subplots(figsize=(50, 10))\n","# fig, ax = plt.subplots(figsize=(20, 10))\n","\n","predict_c1.plot(x_data, y_data_c1 , 'r', label='truth_c1')\n","predict_c2.plot(x_data, y_data_c2 , 'r', label='truth_c2')\n","predict_c3.plot(x_data, y_data_c3 , 'r', label='truth_c3')\n","predict_c1.plot(x_data, y_predict1_c1 , 'b', label='predict1_c1')\n","predict_c2.plot(x_data, y_predict1_c2 , 'b', label='predict1_c2')\n","predict_c3.plot(x_data, y_predict1_c3 , 'b', label='predict1_c3')\n","from sklearn.metrics import r2_score\n","r2_score(Test_label, comparision1, multioutput='raw_values')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXceKoOMaIMv","colab_type":"code","colab":{}},"source":["# !cat ~/.keras/keras.json\n","\n","# from keras import backend\n","# backend.set_image_data_format('channels_first')\n","# print(backend.image_data_format())\n","\n","# !cat ~/.keras/keras.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYOiIdMub_Xa","colab_type":"code","colab":{}},"source":["# # print(open(\"~/.keras/keras.json\").read())\n","# content = {\"epsilon\": 1e-07, \n","#     \"floatx\": \"float32\", \n","#     \"image_data_format\": \"channels_first\", \n","#     \"backend\": \"tensorflow\"}\n","# with open(\" ~/.keras/keras.json\",'w') as f:\n","#   f.write(str(content))\n","# # print(open(\"~/.keras/keras.json\").read())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pyDCEiQh9rK","colab_type":"code","colab":{}},"source":["\n","# tmp = data2[3,0,:,:]\n","# # np.set_printoptions(threshold=np.inf)  #打印全部内容 没有缩写\n","# print(tmp.shape)\n","# # print(tmp[:,:])\n","# tmp=tmp.astype(np.float) # conver to float  and plot \n","# # %matplotlib qt \n","# %matplotlib inline\n","# plt.imshow(tmp,cmap='GnBu')\n","# plt.savefig('/content/drive/My Drive/input_example.png' ,dpi=2400)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGpGISKqqn8J","colab_type":"code","colab":{}},"source":["# aaa = np.load('/content/drive/My Drive/output/M2.npy')\n","# ppp = aaa[0]\n","# print(ppp.shape)\n","# ppp=ppp.astype(np.float) # conver to float  and plot \n","# # %matplotlib qt \n","# %matplotlib inline\n","# plt.imshow(ppp,cmap='gray')\n","# plt.savefig('/content/drive/My Drive/output_example.png' ,dpi=2400)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_GEzrFQzZJk","colab_type":"code","colab":{}},"source":["def SPLIT(data,split):\n","\n","  data, label = shuffle(data, Label, random_state=20)\n","\n","  train_data = data[:split]\n","  train_label = label[:split]\n","  test_data = data[split:]\n","  test_label = label[split:]\n","\n","  return train_data, train_label, test_data, test_label\n","\n","\n","train_data, train_label, test_data, test_label = SPLIT(data,72)\n","# train_data1, train_label1, test_data1, test_label1 = SPLIT(data1,72)\n","# train_data2, train_label2, test_data2, test_label2 = SPLIT(data2,72)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsKXiWEf__lN","colab_type":"code","colab":{}},"source":["def k_fold(k,train_data,train_targets):\n","  num_val_samples = len(train_data)//k\n","  val_mses = []\n","  val_maes = []\n","  mse_History = []\n","  mae_History = []\n","  num_epochs = 100\n","  batchsize = 6\n","  for i in range(k):\n","    print('processing fold #', i)\n","    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n","    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]], axis=0)\n","    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]], axis=0)\n","    model = threeD_CNN()\n","    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=batchsize, verbose=0)\n","    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n","    mse_history = history.history['loss']\n","    mae_history = history.history['mean_absolute_error']\n","    val_mses.append(val_mse)\n","    val_maes.append(val_mae)\n","    mse_History.append(mse_history)\n","    mae_History.append(mae_history)\n","  return val_mses, val_maes, mse_History, mae_History\n","\n","val_mses, val_maes, mse_history, mae_history = k_fold(4,train_data,train_label)\n","\n","\n","average_mae_history = [(np.mean([x[i] for x in mae_history]))*100 for i in range(100)] \n","average_mse_history = [(np.mean([x[i] for x in mse_history]))*100 for i in range(100)] \n","#model 3Dcnn \n","epochs = range(1,len(average_mse_history)+1)\n","plt.plot(epochs, average_mae_history,'c',  label='mae' )\n","plt.plot(epochs, average_mse_history,'m',  label='mse' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUwIEUOgnscX","colab_type":"code","colab":{}},"source":["def k_fold(k,train_data,train_targets):\n","  num_val_samples = len(train_data)//k\n","  val_mses = []\n","  val_maes = []\n","  mse_History = []\n","  mae_History = []\n","  num_epochs = 100\n","  batchsize = 6\n","  for i in range(k):\n","    print('processing fold #', i)\n","    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n","    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]], axis=0)\n","    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]], axis=0)\n","    model = threeD_CNN1()\n","    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=batchsize, verbose=0)\n","    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n","    mse_history = history.history['loss']\n","    mae_history = history.history['mean_absolute_error']\n","    val_mses.append(val_mse)\n","    val_maes.append(val_mae)\n","    mse_History.append(mse_history)\n","    mae_History.append(mae_history)\n","  return val_mses, val_maes, mse_History, mae_History\n","\n","val_mses1, val_maes1, mse_history1, mae_history1 = k_fold(4,train_data,train_label) \n","\n","average_mae_history1 = [(np.mean([x[i] for x in mae_history1]))*100 for i in range(100)] \n","average_mse_history1= [(np.mean([x[i] for x in mse_history1]))*100 for i in range(100)] \n","#model 3Dcnn \n","epochs = range(1,len(average_mse_history1)+1)\n","plt.plot(epochs, average_mae_history1,'c',  label='mae' )\n","plt.plot(epochs, average_mse_history1,'m',  label='mse' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation')\n","plt.show()\n","# batchsize = 6\n","# model1 = threeD_CNN()\n","# history1 = model1.fit(train_data, train_label, epochs = 100, batch_size = batchsize, verbose=0)\n","# model2 = threeD_CNN1()\n","# history2 = model2.fit(train_data, train_label, epochs = 100, batch_size = batchsize,verbose=0)\n","# model3 = threeD_CNN2()\n","# history3 = model3.fit(train_data, train_label, epochs = 100,batch_size = batchsize, verbose=0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0A6aSD2LpEQG","colab_type":"code","colab":{}},"source":["def k_fold(k,train_data,train_targets):\n","  num_val_samples = len(train_data)//k\n","  val_mses = []\n","  val_maes = []\n","  mse_History = []\n","  mae_History = []\n","  num_epochs = 100\n","  batchsize = 6\n","  for i in range(k):\n","    print('processing fold #', i)\n","    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n","    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n","    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]], axis=0)\n","    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]], axis=0)\n","    model = threeD_CNN2()\n","    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=batchsize, verbose=0)\n","    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n","    mse_history = history.history['loss']\n","    mae_history = history.history['mean_absolute_error']\n","    val_mses.append(val_mse)\n","    val_maes.append(val_mae)\n","    mse_History.append(mse_history)\n","    mae_History.append(mae_history)\n","  return val_mses, val_maes, mse_History, mae_History\n","\n","val_mses2, val_maes2, mse_history2, mae_history2 = k_fold(4,train_data,train_label) \n","\n","average_mae_history2 = [(np.mean([x[i] for x in mae_history2]))*100 for i in range(100)] \n","average_mse_history2 = [(np.mean([x[i] for x in mse_history2]))*100 for i in range(100)] \n","#model 3Dcnn \n","epochs = range(1,len(average_mse_history2)+1)\n","plt.plot(epochs, average_mae_history2,'c',  label='mae' )\n","plt.plot(epochs, average_mse_history2,'m',  label='mse' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation')\n","plt.show()\n","# batchsize = 6\n","# model1 = threeD_CNN()\n","# history1 = model1.fit(train_data, train_label, epochs = 100, batch_size = batchsize, verbose=0)\n","# model2 = threeD_CNN1()\n","# history2 = model2.fit(train_data, train_label, epochs = 100, batch_size = batchsize,verbose=0)\n","# model3 = threeD_CNN2()\n","# history3 = model3.fit(train_data, train_label, epochs = 100,batch_size = batchsize, verbose=0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FmpFlXNrLxD","colab_type":"code","colab":{}},"source":["epochs = range(1,len(average_mse_history)+1)\n","plt.plot(epochs, average_mae_history,'c',  label='mae' )\n","plt.plot(epochs, average_mse_history,'c--',  label='mse' )\n","plt.plot(epochs, average_mae_history1,'m',  label='mae1' )\n","plt.plot(epochs, average_mse_history1,'m--',  label='mse1' )\n","plt.plot(epochs, average_mae_history2,'r',  label='mae2' )\n","plt.plot(epochs, average_mse_history2,'r--',  label='mse2' )\n","plt.xlabel('Epochs')\n","plt.ylabel('Average_performance')\n","plt.legend()\n","# plt.show()\n","plt.savefig('/content/drive/My Drive/original_30_3models_comparison.png' ,dpi=1200)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y2k-IciUBMET","colab_type":"code","colab":{}},"source":["mse1 = history1.history['loss']\n","mae1 = history1.history['mean_absolute_error']\n","mse2 = history2.history['loss']\n","mae2 = history2.history['mean_absolute_error']\n","mse3 = history3.history['loss']\n","mae3 = history3.history['mean_absolute_error']\n","# val_loss = history.history['val_loss']\n","# acc = history.history['acc']\n","# val_acc=history.history['val_acc']\n","epochs = range(1,len(mse1) +1)\n","plt.plot(epochs, mse1, 'c', label='mse1')\n","plt.plot(epochs, mse2, 'm', label='mse2')\n","plt.plot(epochs, mse3, 'r', label='mse3')\n","\n","plt.plot(epochs, mae1, 'c--', label='mae1')\n","plt.plot(epochs, mae2, 'm--', label='mae2')\n","plt.plot(epochs, mae3, 'r--', label='mae3')\n","\n","plt.title('loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show() \n","# plt.savefig('/content/drive/My Drive/original_30_3models_comparison.png' ,dpi=2400)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCiqhmnb0SrP","colab_type":"code","colab":{}},"source":["comparision1 = (model1.predict(test_data))*100\n","comparision2 =(model2.predict(test_data))*100\n","comparision3 = (model3.predict(test_data))*100\n","print(comparision1[0,0])\n","print(comparision2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oorCp3DpyDY","colab_type":"code","colab":{}},"source":["x_data = range(24)\n","Test_label = test_label*100\n","y_data_c1 = Test_label[:,0]\n","y_data_c2 = Test_label[:,1]\n","y_data_c3 = Test_label[:,2]\n","y_predict1_c1 = comparision1[:,0]\n","y_predict1_c2 = comparision1[:,1]\n","y_predict1_c3 = comparision1[:,2]\n","y_predict2_c1 = comparision2[:,0]\n","y_predict2_c2 = comparision2[:,1]\n","y_predict2_c3 = comparision2[:,2]\n","y_predict3_c1 = comparision3[:,0]\n","y_predict3_c2 = comparision3[:,1]\n","y_predict3_c3 = comparision3[:,2]\n","\n","fig, (predict_c1, predict_c2, predict_c3) = plt.subplots(3)\n","fig.suptitle('3 visual conditions') \n","\n","\n","predict_c1.plot(x_data, y_data_c1 , 'c', label='truth_c1')\n","predict_c2.plot(x_data, y_data_c2 , 'r', label='truth_c2')\n","predict_c3.plot(x_data, y_data_c3 , 'b', label='truth_c3')\n","predict_c1.plot(x_data, y_predict1_c1 , 'c--', label='predict1_c1')\n","predict_c2.plot(x_data, y_predict1_c2 , 'r--', label='predict1_c2')\n","predict_c3.plot(x_data, y_predict1_c3 , 'b--', label='predict1_c3')\n","predict_c1.plot(x_data, y_predict2_c1 , 'c:', label='predict2_c1')\n","predict_c2.plot(x_data, y_predict2_c2 , 'r:', label='predict2_c2')\n","predict_c3.plot(x_data, y_predict2_c3 , 'b:', label='predict2_c3')\n","predict_c1.plot(x_data, y_predict3_c1 , 'c-.', label='predict2_c1')\n","predict_c2.plot(x_data, y_predict3_c2 , 'r-.', label='predict2_c2')\n","predict_c3.plot(x_data, y_predict3_c3 , 'b-.', label='predict2_c3')\n","\n","predict_c1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n","predict_c2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n","predict_c3.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n","\n","# plt.title('loss')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.show() \n","# fig.savefig('/content/drive/My Drive/ready_data_6C/matrix_input/1.png' ,bbox_inches='tight')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eeafspWL5hF-","colab_type":"code","colab":{}},"source":["print(comparision1.shape)\n","y_data_c1 = test_label[:,0]\n","print(y_data_c1.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4Nj-8wBb-YS","colab_type":"code","colab":{}},"source":["def calculate_mse(predict):   #对比三种视觉情况 每个model的mse  \n","  y_data_c1 = test_label[:,0]\n","  y_data_c2 = test_label[:,1]\n","  y_data_c3 = test_label[:,2]\n","  y_predict1_c1 = predict[:,0]\n","  y_predict1_c2 = predict[:,1]\n","  y_predict1_c3 = predict[:,2]\n","  tmp1 = 0\n","  tmp2 = 0\n","  tmp3 = 0\n","  for i in range(24):\n","    tmp1 = tmp1 + (y_data_c1[i]- y_predict1_c1[i])**2\n","    tmp2 = tmp2 + (y_data_c2[i]- y_predict1_c2[i])**2\n","    tmp3 = tmp3 + (y_data_c3[i]- y_predict1_c3[i])**2\n","  c1 = tmp1 /24 \n","  c2 = tmp2 /24\n","  c3 = tmp3 /24\n","  # c1 = K.mean(K.square( y_data_c1- y_predict1_c1), axis=-1)\n","  # c2 = K.mean(K.square( y_data_c2- y_predict1_c2), axis=-1)\n","  # c3 = K.mean(K.square( y_data_c3- y_predict1_c3), axis=-1)\n","  return c1 , c2 ,c3 \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ADIMW3_z6wqi","colab_type":"code","colab":{}},"source":["# from keras import backend as K\n","Model1 = calculate_mse(comparision1)\n","Model2 = calculate_mse(comparision2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtVJRcL-630S","colab_type":"code","colab":{}},"source":["print(Model1)\n","print(Model2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOibpL9D7oal","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}